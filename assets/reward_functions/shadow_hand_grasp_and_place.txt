import torch
from typing import Tuple, Dict

@torch.jit.script
def compute_reward(object_pos: torch.Tensor, left_hand_pos: torch.Tensor, right_hand_pos: torch.Tensor,
                   goal_pos: torch.Tensor, object_rot: torch.Tensor, goal_rot: torch.Tensor,
                   object_linvel: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:

    object_goal_distance = torch.norm(object_pos - goal_pos, dim=-1)

    left_hand_distance = torch.norm(left_hand_pos - object_pos, dim=-1)
    right_hand_distance = torch.norm(right_hand_pos - object_pos, dim=-1)
    hand_distance = (left_hand_distance + right_hand_distance) / 2.0

    goal_rot_distance = 1.0 - torch.sum(object_rot * goal_rot, dim=-1)

    # Use a sigmoid function to facilitate grabbing success
    grab_success_temperature = 5.0
    grab_success = torch.sigmoid(grab_success_temperature * (1.0 - hand_distance))

    # Penalty for object instability while being held
    object_instability_penalty = torch.norm(object_linvel, dim=-1)

    reward_distance_temperature = 0.05  # Weaken the influence of distance_reward
    reward_rot_temperature = 2.0         # Strengthen the influence of rot_reward
    reward_hand_distance_temperature = 0.1
    reward_instability_penalty_temperature = 1.0

    distance_reward = torch.exp(-reward_distance_temperature * object_goal_distance)
    rot_reward = torch.exp(-reward_rot_temperature * goal_rot_distance)
    hand_distance_reward = torch.exp(-reward_hand_distance_temperature * hand_distance)
    instability_penalty = torch.exp(-reward_instability_penalty_temperature * object_instability_penalty)

    # Include grab_success and instability_penalty in the total_reward calculation
    total_reward = torch.abs(distance_reward - 1.0) * grab_success \
                    + torch.abs(rot_reward - 1.0) * grab_success \
                    + hand_distance_reward \
                    - instability_penalty

    reward_components = {"distance_reward": distance_reward, "rot_reward": rot_reward,
                         "hand_distance_reward": hand_distance_reward, "grab_success": grab_success,
                         "instability_penalty": instability_penalty}

    return total_reward, reward_components
