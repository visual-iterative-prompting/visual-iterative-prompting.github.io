import torch
from typing import Tuple, Dict

@torch.jit.script
def compute_reward(object_pos: torch.Tensor, block_pos: torch.Tensor, goal_pos: torch.Tensor, right_hand_pos: torch.Tensor, left_hand_pos: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
    block_distance_temperature = 4.0
    hands_distance_temperature = 1.0
    stacking_reward_temperature = 5.0
    success_reward_multiplier = 20.0
    proximity_reward_temperature = 2.0

    block1_pos = object_pos
    block2_pos = block_pos

    # Calculate distance between the two blocks
    block_distance = torch.norm(block1_pos - block2_pos, dim=-1)
    block_distance_reward = torch.exp(-block_distance_temperature * block_distance)

    # Calculate distance between the blocks and the goal position
    block1_goal_distance = torch.norm(goal_pos - block1_pos, dim=-1)
    block2_goal_distance = torch.norm(goal_pos - block2_pos, dim=-1)

    # Calculate distance between both hands and blocks
    right_hand_block1_distance = torch.norm(right_hand_pos - block1_pos, dim=-1)
    left_hand_block1_distance = torch.norm(left_hand_pos - block1_pos, dim=-1)
    right_hand_block2_distance = torch.norm(right_hand_pos - block2_pos, dim=-1)
    left_hand_block2_distance = torch.norm(left_hand_pos - block2_pos, dim=-1)

    # Encourage both hands to be near the blocks
    hands_distance_reward = torch.exp(-hands_distance_temperature * (right_hand_block1_distance + left_hand_block1_distance + right_hand_block2_distance + left_hand_block2_distance))

    # Success-based reward
    success_threshold = 0.02
    successful_stack = torch.where(torch.logical_and(block1_goal_distance < success_threshold, block2_goal_distance < success_threshold), torch.tensor(1.0, device=object_pos.device), torch.tensor(0.0, device=object_pos.device))
    success_reward = success_reward_multiplier * successful_stack

    # Stacking-based reward
    stacking_threshold = 0.05
    stacking_condition = torch.where(block_distance < stacking_threshold, torch.tensor(1.0, device=object_pos.device), torch.tensor(0.0, device=object_pos.device))
    stacking_reward = stacking_reward_temperature * stacking_condition

    # Proximity-based reward
    block_proximity = (block1_goal_distance + block2_goal_distance) / 2
    proximity_reward = torch.exp(-proximity_reward_temperature * block_proximity)

    # Total reward is a combination of block_distance_reward, hands_distance_reward, success_reward, stacking_reward, and proximity_reward
    total_reward = block_distance_reward + hands_distance_reward + success_reward + stacking_reward + proximity_reward

    reward_dict = {
        "block_distance_reward": block_distance_reward,
        "hands_distance_reward": hands_distance_reward,
        "success_reward": success_reward,
        "stacking_reward": stacking_reward,
        "proximity_reward": proximity_reward
    }

    return total_reward, reward_dict
