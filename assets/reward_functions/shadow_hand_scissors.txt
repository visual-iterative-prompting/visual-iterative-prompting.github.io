import torch
from typing import Tuple, Dict

@torch.jit.script
def compute_reward(scissors_right_handle_pos: torch.Tensor, scissors_left_handle_pos: torch.Tensor,
                   right_hand_pos: torch.Tensor, left_hand_pos: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:

    target_opened_distance = 0.3  # Set the desired opened distance between the scissors" handles when opened
    opened_reward_temp = 5.0  # Change the value to adjust the sensitivity of the opened scissors reward component

    # Calculate the distance between the right and left handles of the scissors
    handle_distance = torch.norm(scissors_right_handle_pos - scissors_left_handle_pos, dim=-1)

    # Calculate the reward based on the opened distance of the scissors
    opened_reward = torch.exp(opened_reward_temp * (handle_distance - target_opened_distance))

    # Calculate the distance between the hands and the corresponding handles of the scissors
    right_hand_to_handle_dist = torch.norm(right_hand_pos - scissors_right_handle_pos, dim=-1)
    left_hand_to_handle_dist = torch.norm(left_hand_pos - scissors_left_handle_pos, dim=-1)

    # Penalize the agent if the hands are too far from the handles
    handle_reaching_penalty = 0.5 * (right_hand_to_handle_dist + left_hand_to_handle_dist)

    # Calculate the total reward
    total_reward = opened_reward - handle_reaching_penalty

    # Log individual rewards for debugging
    reward_info = {
        "opened_reward": opened_reward,
        "handle_reaching_penalty": handle_reaching_penalty
    }

    return total_reward, reward_info
