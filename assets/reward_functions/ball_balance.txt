import torch
from torch import Tensor
from typing import Dict, Tuple

@torch.jit.script
def compute_reward(ball_positions: Tensor, ball_linvels: Tensor, sensor_forces: Tensor, sensor_torques: Tensor) -> Tuple[Tensor, Dict[str, Tensor]]:
    # Reward for maintaining low velocity
    velocity_reward_temperature = 0.01
    velocity_reward = torch.exp(-torch.norm(ball_linvels, dim=-1) * velocity_reward_temperature)

    # Reward for having low forces on the sensors
    force_reward_temperature = 0.0001
    force_reward = torch.exp(-torch.norm(sensor_forces[..., 0], dim=-1) * force_reward_temperature)

    # Reward for having low torques on the sensors
    torque_reward_temperature = 0.0001
    torque_reward = torch.exp(-torch.norm(sensor_torques[..., 0], dim=-1) * torque_reward_temperature)

    # Reward for staying on the surface
    surface_reward = torch.where(ball_positions[..., 2] > 0.0, torch.tensor(1.0, device=ball_positions.device), torch.tensor(0.0, device=ball_positions.device))

    # Combine reward components
    total_reward = velocity_reward * force_reward * torque_reward * surface_reward
    reward_components = {
        "velocity_reward": velocity_reward,
        "force_reward": force_reward,
        "torque_reward": torque_reward,
        "surface_reward": surface_reward
    }

    return total_reward, reward_components
